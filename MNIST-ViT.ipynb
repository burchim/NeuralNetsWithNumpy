{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "SZzAQQCrX68F"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import mnist\n",
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5kWN_H9NsBSN",
    "outputId": "7751cbb5-b7cc-4db5-cd45-28ccc2c0de3f"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/burchim/NeuralNetsWithNumpy.git\n",
    "%cd NeuralNetsWithNumpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "cALwnq3-r0ZX"
   },
   "outputs": [],
   "source": [
    "# Modules\n",
    "from nnet.modules import (\n",
    "  Identity,\n",
    "  Sigmoid,\n",
    "  Tanh,\n",
    "  ReLU,\n",
    "  PReLU,\n",
    "  Swish,\n",
    "  LayerNorm,\n",
    "  BatchNorm\n",
    ")\n",
    "\n",
    "# Optimizers\n",
    "from nnet.optimizers import (\n",
    "  SGD,\n",
    "  RMSprop,\n",
    "  Adam,\n",
    "  AdamW\n",
    ")\n",
    "\n",
    "# Losses\n",
    "from nnet.losses import (\n",
    "  MeanAbsoluteError,\n",
    "  MeanSquaredError,\n",
    "  SoftmaxCrossEntropy\n",
    ")\n",
    "\n",
    "# Schedulers\n",
    "from nnet.schedulers import (\n",
    "  ConstantScheduler,\n",
    "  WarmupCosineAnnealingScheduler\n",
    ")\n",
    "\n",
    "# Model\n",
    "from nnet.models import VisionTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1iSqq89Dr0ZZ",
    "outputId": "501c538f-9819-4ea8-cf87-44d11a17338c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train: (60000, 28, 28)\n",
      "y_train: (60000, 10)\n",
      "x_val:  (10000, 28, 28)\n",
      "y_val:  (10000, 10)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Seed\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "\n",
    "# dtype\n",
    "dtype = np.float32\n",
    "\n",
    "# Load Dataset\n",
    "(x_train, y_train), (x_val, y_val) = mnist.load_data()\n",
    "\n",
    "# Prepare Dataset\n",
    "x_train = (x_train/255).astype(dtype)\n",
    "y_train = to_categorical(y_train).astype(dtype)\n",
    "x_val = (x_val/255).astype(dtype)\n",
    "y_val = to_categorical(y_val).astype(dtype)\n",
    "\n",
    "# shapes\n",
    "print('x_train: ' + str(x_train.shape))\n",
    "print('y_train: ' + str(y_train.shape))\n",
    "print('x_val:  '  + str(x_val.shape))\n",
    "print('y_val:  '  + str(y_val.shape))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "WYefD1Zvr0Za"
   },
   "outputs": [],
   "source": [
    "# Params\n",
    "epochs = 5\n",
    "batch_size = 32\n",
    "optimizer = AdamW\n",
    "scheduler = WarmupCosineAnnealingScheduler\n",
    "\n",
    "in_height = 28\n",
    "in_width = 28\n",
    "in_dim = 1\n",
    "\n",
    "patch_size = 4\n",
    "dim_model = 32\n",
    "ff_ratio = 4\n",
    "num_heads = 4\n",
    "num_blocks = 2\n",
    "drop_rate = 0.1\n",
    "out_dim = 10\n",
    "dim_mlp_layers = [128, out_dim]\n",
    "mlp_norm = LayerNorm\n",
    "hidden_function = ReLU\n",
    "out_function = Identity\n",
    "loss_function = SoftmaxCrossEntropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oUiD-vRXr0Zb",
    "outputId": "52f5ebc5-3c93-49f9-8756-029e44e66617"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "229898 parameters\n",
      "embedding.linear.weight                                        shape (16, 32)         mean 0.0016       std 0.2578       dtype float32     \n",
      "embedding.linear.bias                                          shape (32,)            mean 0.0000       std 0.0000       dtype float32     \n",
      "pos_encoding.embeddings                                        shape (49, 32)         mean 0.0491       std 0.9994       dtype float32     \n",
      "blocks.0.TransformerBlock.mhsa_module.layernorm.gamma          shape (32,)            mean 1.0000       std 0.0000       dtype float32     \n",
      "blocks.0.TransformerBlock.mhsa_module.layernorm.beta           shape (32,)            mean 0.0000       std 0.0000       dtype float32     \n",
      "blocks.0.TransformerBlock.mhsa_module.mhsa.query_layer.weight  shape (32, 32)         mean 0.0007       std 0.1780       dtype float32     \n",
      "blocks.0.TransformerBlock.mhsa_module.mhsa.query_layer.bias    shape (32,)            mean 0.0000       std 0.0000       dtype float32     \n",
      "blocks.0.TransformerBlock.mhsa_module.mhsa.key_layer.weight    shape (32, 32)         mean -0.0103      std 0.1738       dtype float32     \n",
      "blocks.0.TransformerBlock.mhsa_module.mhsa.key_layer.bias      shape (32,)            mean 0.0000       std 0.0000       dtype float32     \n",
      "blocks.0.TransformerBlock.mhsa_module.mhsa.value_layer.weight  shape (32, 32)         mean -0.0002      std 0.1769       dtype float32     \n",
      "blocks.0.TransformerBlock.mhsa_module.mhsa.value_layer.bias    shape (32,)            mean 0.0000       std 0.0000       dtype float32     \n",
      "blocks.0.TransformerBlock.mhsa_module.mhsa.output_layer.weight shape (32, 32)         mean -0.0013      std 0.1783       dtype float32     \n",
      "blocks.0.TransformerBlock.mhsa_module.mhsa.output_layer.bias   shape (32,)            mean 0.0000       std 0.0000       dtype float32     \n",
      "blocks.0.TransformerBlock.ff_module.layernorm.gamma            shape (32,)            mean 1.0000       std 0.0000       dtype float32     \n",
      "blocks.0.TransformerBlock.ff_module.layernorm.beta             shape (32,)            mean 0.0000       std 0.0000       dtype float32     \n",
      "blocks.0.TransformerBlock.ff_module.linear1.weight             shape (32, 128)        mean -0.0045      std 0.1743       dtype float32     \n",
      "blocks.0.TransformerBlock.ff_module.linear1.bias               shape (128,)           mean 0.0000       std 0.0000       dtype float32     \n",
      "blocks.0.TransformerBlock.ff_module.linear2.weight             shape (128, 32)        mean 0.0001       std 0.0894       dtype float32     \n",
      "blocks.0.TransformerBlock.ff_module.linear2.bias               shape (32,)            mean 0.0000       std 0.0000       dtype float32     \n",
      "blocks.1.TransformerBlock.mhsa_module.layernorm.gamma          shape (32,)            mean 1.0000       std 0.0000       dtype float32     \n",
      "blocks.1.TransformerBlock.mhsa_module.layernorm.beta           shape (32,)            mean 0.0000       std 0.0000       dtype float32     \n",
      "blocks.1.TransformerBlock.mhsa_module.mhsa.query_layer.weight  shape (32, 32)         mean -0.0050      std 0.1753       dtype float32     \n",
      "blocks.1.TransformerBlock.mhsa_module.mhsa.query_layer.bias    shape (32,)            mean 0.0000       std 0.0000       dtype float32     \n",
      "blocks.1.TransformerBlock.mhsa_module.mhsa.key_layer.weight    shape (32, 32)         mean 0.0036       std 0.1762       dtype float32     \n",
      "blocks.1.TransformerBlock.mhsa_module.mhsa.key_layer.bias      shape (32,)            mean 0.0000       std 0.0000       dtype float32     \n",
      "blocks.1.TransformerBlock.mhsa_module.mhsa.value_layer.weight  shape (32, 32)         mean 0.0082       std 0.1739       dtype float32     \n",
      "blocks.1.TransformerBlock.mhsa_module.mhsa.value_layer.bias    shape (32,)            mean 0.0000       std 0.0000       dtype float32     \n",
      "blocks.1.TransformerBlock.mhsa_module.mhsa.output_layer.weight shape (32, 32)         mean 0.0120       std 0.1757       dtype float32     \n",
      "blocks.1.TransformerBlock.mhsa_module.mhsa.output_layer.bias   shape (32,)            mean 0.0000       std 0.0000       dtype float32     \n",
      "blocks.1.TransformerBlock.ff_module.layernorm.gamma            shape (32,)            mean 1.0000       std 0.0000       dtype float32     \n",
      "blocks.1.TransformerBlock.ff_module.layernorm.beta             shape (32,)            mean 0.0000       std 0.0000       dtype float32     \n",
      "blocks.1.TransformerBlock.ff_module.linear1.weight             shape (32, 128)        mean 0.0075       std 0.1777       dtype float32     \n",
      "blocks.1.TransformerBlock.ff_module.linear1.bias               shape (128,)           mean 0.0000       std 0.0000       dtype float32     \n",
      "blocks.1.TransformerBlock.ff_module.linear2.weight             shape (128, 32)        mean -0.0007      std 0.0874       dtype float32     \n",
      "blocks.1.TransformerBlock.ff_module.linear2.bias               shape (32,)            mean 0.0000       std 0.0000       dtype float32     \n",
      "mlp.0.Linear.weight                                            shape (1568, 128)      mean 0.0000       std 0.0253       dtype float32     \n",
      "mlp.0.Linear.bias                                              shape (128,)           mean 0.0000       std 0.0000       dtype float32     \n",
      "mlp.0.LayerNorm.gamma                                          shape (128,)           mean 1.0000       std 0.0000       dtype float32     \n",
      "mlp.0.LayerNorm.beta                                           shape (128,)           mean 0.0000       std 0.0000       dtype float32     \n",
      "mlp.1.Linear.weight                                            shape (128, 10)        mean 0.0017       std 0.0882       dtype float32     \n",
      "mlp.1.Linear.bias                                              shape (10,)            mean 0.0000       std 0.0000       dtype float32     \n"
     ]
    }
   ],
   "source": [
    "# Create Model\n",
    "model = VisionTransformer(\n",
    "  in_height=in_height, \n",
    "  in_width=in_width, \n",
    "  in_dim=in_dim, \n",
    "  patch_size=patch_size,\n",
    "  num_blocks=num_blocks,\n",
    "  dim_model=dim_model,\n",
    "  ff_ratio=ff_ratio,\n",
    "  num_heads=num_heads,\n",
    "  drop_rate=drop_rate,\n",
    "  dim_mlp_layers=dim_mlp_layers,\n",
    "  mlp_norm=mlp_norm,\n",
    "  hidden_function=hidden_function,\n",
    "  out_function=out_function,\n",
    "  loss_function=loss_function,\n",
    "  dtype=dtype\n",
    ")\n",
    "\n",
    "model.optimizer = optimizer(model.get_parameters(), lr=0, betas=(0.9, 0.999), eps=1e-8)\n",
    "model.scheduler = scheduler(model.optimizer, warmup_steps=len(x_train) // batch_size, lr_max=0.005, lr_min=0.00005, end_step=5*len(x_train) // batch_size)\n",
    "\n",
    "# Model Summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bAqoL91fr0Zd",
    "outputId": "e25dc47d-2c6b-4773-8a5f-4cfdedba48ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train: (1875, 32, 28, 28)\n",
      "y_train: (1875, 32, 10)\n",
      "x_val: (312, 32, 28, 28)\n",
      "y_val: (312, 32, 10)\n"
     ]
    }
   ],
   "source": [
    "# Batch Training set\n",
    "train_len = len(x_train)\n",
    "overflow = train_len % batch_size\n",
    "x_train = x_train[:train_len-overflow]\n",
    "y_train = y_train[:train_len-overflow]\n",
    "x_train = np.reshape(x_train, (-1, batch_size, in_height, in_width))\n",
    "y_train = np.reshape(y_train, (-1, batch_size, out_dim))\n",
    "\n",
    "print('x_train: ' + str(x_train.shape))\n",
    "print('y_train: ' + str(y_train.shape))\n",
    "\n",
    "# Batch validation set\n",
    "val_len = len(x_val)\n",
    "overflow = val_len % batch_size\n",
    "x_val = x_val[:val_len-overflow]\n",
    "y_val = y_val[:val_len-overflow]\n",
    "x_val = np.reshape(x_val, (-1, batch_size, in_height, in_width))\n",
    "y_val = np.reshape(y_val, (-1, batch_size, out_dim))\n",
    "\n",
    "print('x_val: ' + str(x_val.shape))\n",
    "print('y_val: ' + str(y_val.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CmcLF5ncr0Zg",
    "outputId": "9df5dabf-96a6-4bcf-fa96-7fb5ae38410f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mean loss: 0.3800 - batch loss: 0.2495 - mean acc: 88.40 - batch acc: 93.75 - lr: 0.005000 - step: 1875: 100%|█████| 1875/1875 [01:48<00:00, 17.22it/s]\n",
      "mean loss: 0.1257 - batch loss: 0.1067 - mean acc: 96.14 - batch acc: 93.75: 100%|███████████████████████████████████| 312/312 [00:05<00:00, 58.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 0.1257\n",
      "validation accuracy: 96.14%\n",
      "\n",
      "Epoch 2/5:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mean loss: 0.1215 - batch loss: 0.0974 - mean acc: 96.25 - batch acc: 96.88 - lr: 0.004275 - step: 3750: 100%|█████| 1875/1875 [01:31<00:00, 20.47it/s]\n",
      "mean loss: 0.0821 - batch loss: 0.0508 - mean acc: 97.49 - batch acc: 100.00: 100%|██████████████████████████████████| 312/312 [00:05<00:00, 56.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 0.0821\n",
      "validation accuracy: 97.49%\n",
      "\n",
      "Epoch 3/5:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mean loss: 0.0747 - batch loss: 0.2189 - mean acc: 97.66 - batch acc: 93.75 - lr: 0.002525 - step: 5625: 100%|█████| 1875/1875 [01:36<00:00, 19.34it/s]\n",
      "mean loss: 0.0473 - batch loss: 0.0642 - mean acc: 98.49 - batch acc: 96.88: 100%|███████████████████████████████████| 312/312 [00:08<00:00, 35.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 0.0473\n",
      "validation accuracy: 98.49%\n",
      "\n",
      "Epoch 4/5:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mean loss: 0.0448 - batch loss: 0.0026 - mean acc: 98.61 - batch acc: 100.00 - lr: 0.000775 - step: 7500: 100%|████| 1875/1875 [01:41<00:00, 18.45it/s]\n",
      "mean loss: 0.0372 - batch loss: 0.0178 - mean acc: 98.86 - batch acc: 100.00: 100%|██████████████████████████████████| 312/312 [00:04<00:00, 64.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 0.0372\n",
      "validation accuracy: 98.86%\n",
      "\n",
      "Epoch 5/5:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mean loss: 0.0236 - batch loss: 0.0201 - mean acc: 99.32 - batch acc: 100.00 - lr: 0.000050 - step: 9375: 100%|████| 1875/1875 [01:43<00:00, 18.14it/s]\n",
      "mean loss: 0.0327 - batch loss: 0.0165 - mean acc: 98.90 - batch acc: 100.00: 100%|██████████████████████████████████| 312/312 [00:09<00:00, 33.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 0.0327\n",
      "validation accuracy: 98.90%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Train Model\n",
    "model.fit(\n",
    "  dataset_train=(x_train, y_train),\n",
    "  epochs=epochs,\n",
    "  dataset_val=(x_val, y_val)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l__lzPnfr0Zl"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "MNIST.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
